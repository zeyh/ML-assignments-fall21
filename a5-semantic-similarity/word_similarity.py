import math
from scipy.stats import spearmanr
from embeddings import Embeddings
import numpy as np

def read_simlex(embeddings, infile = 'data/SimLex-999.txt'):
    simlex = {}
    for idx, item in enumerate(open(infile)):
        if idx == 0: continue
        w1, w2, pos, val = item.strip().lower().split('\t')[0:4]
        if pos != 'n': continue
        if not (w1 in embeddings and w2 in embeddings): continue
        simlex[(w1,w2)] = float(val) / 10.0
    return simlex

def read_wordsim(embeddings, infile = 'data/wordsim353_set2.tab'):
    wordsim = {}
    for idx, item in enumerate(open(infile)):
        if idx == 0: continue
        w1, w2, val = item.strip().lower().split('\t')[0:3]
        if not (w1 in embeddings and w2 in embeddings): continue
        wordsim[(w1,w2)] = float(val) / 10.0
    return wordsim

def score_word_dataset(embeddings, dataset):
    """
    Calculate Spearman's Rho for word similarity on the given dataset.

    The dataset is obtained from the read_simlex or read_wordsim functions.

    To do this, collect lists of the gold similarity values and the
    model values generated by word embedding similarity, and pass
    both lists to the spearmanr function. The spearmanr function
    has two return values, you want to return only the first one.

    Parameters
    ----------
    dataset : dict of the form { (word, word) : similarity_val }
        WordSim-353 or SimLex-999 dataset.

    Returns
    -------
    float
        The Spearman's Rho ranked correlation coefficient between 
        the emeddings and the human judgments.
    """
    vec1 = np.asarray(list(dataset.values()))
    vec2 = np.zeros(len(dataset))

    for i,d in enumerate(dataset):
        vec2[i] = embeddings.cosine_similarity(d[0], d[1])
    return spearmanr(vec1, vec2).correlation
    


if __name__ == '__main__':
    embeddings = Embeddings(glove_file = "data/glove_top50k_50d.txt")    

    # simlex = read_simlex(embeddings)
    # wordsim = read_wordsim(embeddings)
    # test_dataset = {('boat', 'float'): 0.5, ('moat','coat'): 0.1, ('note','vote'): 0.9} 
    # print('WordSim-353 score:', score_word_dataset(embeddings, test_dataset))
    # print('SimLex-999 score:', score_word_dataset(embeddings, simlex))
    

